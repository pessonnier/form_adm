2019-04-23

# liens précédents
https://www.dropbox.com/sh/bd5u25rchj34fww/AAA8y_Xnum2bLVIJSGJADYMda?dl=0
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      

https://notepad.pw/Mfobiginfra
https://www.dropbox.com/sh/kegxsmoknkj9vxp/AABLPKh_RKZgLtD7kzfooMoDa?dl=0

sudo docker ps
... container ID
ps : n'oublie pas ton mot de passe sinon j y peux rien
sudo docker exec -it containerid bash ou hive ou ce que tu veux ...

ALTER TABLE toto    
set serde 'org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe'
WITH SERDEPROPERTIES ('field.delim' = ',');
https://hds-streaming.com/episodes/game-of-thrones-saison-8-episode-1-streaming/

http://localhost:8888/jobbrowser/``

https://logisima.developpez.com/tutoriel/nosql/neo4j/introduction-neo4j/

select * from regions r, departments d where r.code = d.region_code

sudo apt install openjdk-8-jdk


https://github.com/dpkp/kafka-python

# datalake
multiple source
ingérer
structurer
netoyer
extraire
ML

# hadoop
hive utilise mapreduce
impala utilise directement yarn

## hdfs
manipulation de fichier avec
- hdfs dfs -XXX
- hadoop fs -XXX

## hbase
hbase shell

# hive

create table wh_visits 
(lname string,
 fname string,
 time_of_arrival string,
 appt_scheduled_time string,
 meeting_location string,
 info_comment string)
ROW FORMAT DELIMITED
FIELDS TERMINATED BY '\t'

hive -f xxx.hive

select input__file__name, BLOCK__OFFSET__INSIDE__FILE, lname from wh_visits;

create table names (id int, name string)
ROW FORMAT DELIMITED
FIELDS TERMINATED BY '\t';

hdfs dfs -put /src/names.txt /user/hive/warehouse/names
drop table names;
le dossier est supprimé

create external table names2 (id int, name string)
ROW FORMAT DELIMITED
FIELDS TERMINATED BY '\t'
location '/user/cloudera/names2';

load data inpath '/user/cloudera/entree/names.txt' into table names2;
le fichier est déplacé

drop table names2;
le fichier reste dans /user/cloudera/names2

select * from wh_visits where time_of_arrival !=""
order by unix_timestamp(time_of_arrival, 'MM/dd/yyyy hh:mm');

explain extended select count(info_comment) as n, info_comment from wh_visits
group by info_comment
order by n desc
limit 10;

# spark
docker run -v `pwd`:/home/guest/host -p 4040:4040 -p 8889:8888 -p 23:22 -ti --privileged yannael/kafka-sparkstreaming-cassandra
